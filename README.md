# Relativistic Interpretability

A framework exploring how neural networks might process information through multiple geometric lenses simultaneously.

## Core Idea

Different types of information might route through different geometric attention patterns:
- Sequential → Square geometry
- Associative → Hexagonal geometry  
- Hierarchical → Triangular geometry
- Novel/Creative → Pentagonal geometry

## Connection to Empirical Work

This framework attempts to interpret phase distributions found in [ouroboros-learning](https://github.com/HillaryDanan/ouroboros-learning), where GPT-3.5 showed significant non-uniform patterns (p < 0.0001).

## Status

Early-stage theoretical framework. Looking for collaborators to:
- Test the geometric decomposition approach
- Develop better validation methods
- Find alternative interpretations

## Quick Start

```python
# Decompose attention through geometric lenses
geometric_analyzer = RelInterpretabilityAnalyzer()
results = geometric_analyzer.analyze_attention(model, data)
```

## Related Work

- [Multi-Geometric Attention Theory](https://github.com/HillaryDanan/multi-geometric-attention)
- [Ouroboros Learning Study](https://github.com/HillaryDanan/ouroboros-learning)

## Contributing

All ideas welcome. Open an issue or PR if you see potential connections or flaws.

## License

MIT - Free to build on

---

*Exploring how interpretation depends on your reference frame.*
